{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10854,
     "status": "ok",
     "timestamp": 1750829980261,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "5V4XPa3aRFfJ",
    "outputId": "16ce9c9c-c03d-4aed-f9dd-06c474968994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1750657741969,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "V16ijHD0Tyvr",
    "outputId": "9ba89e0c-6f9b-4389-f625-5c6f281ac753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----+\n",
      "|NAME|AGE|dept|\n",
      "+----+---+----+\n",
      "| RAM| 20| cse|\n",
      "|  DK| 20| ece|\n",
      "+----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RAM\").getOrCreate()\n",
    "df =[(\"RAM\",20,\"cse\"),(\"DK\",20,\"ece\")]\n",
    "data= [\"NAME\",\"AGE\",\"dept\"]\n",
    "spark_df=spark.createDataFrame(df,schema=data)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZECUH4C0UQaZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1750659076863,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "jQkdettjZquc",
    "outputId": "df75997c-633d-46bc-f465-32dffcbf69d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  Thiru| 19|\n",
      "|    Ram| 21|\n",
      "|Dhinesh| 22|\n",
      "+-------+---+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Ramspark\").getOrCreate()\n",
    "\n",
    "# Sample DataFrame\n",
    "data = [(\"Thiru\", 19), (\"Ram\", 21), (\"Dhinesh\", 22)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "error",
     "timestamp": 1750659664002,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "28ddwPCFbf5V",
    "outputId": "4f9ac389-71dd-4c7e-c53c-bd85bdcfa97f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'reaad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-20-3244602590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RamSpark\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"student.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferScheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Department\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'reaad'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RamSpark\").getOrCreate\n",
    "df = spark.reaad.csv(\"student.csv\", header=True, inferScheme=True)\n",
    "df.groupBy(\"Department\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7240,
     "status": "ok",
     "timestamp": 1750659747017,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "GOOlM6_Dc1zZ",
    "outputId": "89e58f76-ce5f-46a4-a417-0d87542b1c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1750659930746,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "9kpbGfqedAE8",
    "outputId": "6c4d2fce-f6ad-4ae5-cb4e-950e50e1cf4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RamFirstApp\").getOrCreate()\n",
    "print(\"Spark Version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1750659976409,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "ziAbwjb5dvD2",
    "outputId": "063ce96d-a3b0-4bce-a960-5c63708e70b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1750660116674,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "s-eLMhYLduut",
    "outputId": "92830c02-51b5-4f91-e333-2415811ca1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|Dhinesh| 19|\n",
      "|    Ram| 21|\n",
      "|   Hari| 20|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"HelloRam\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Dhinesh\", 19), (\"Ram\", 21), (\"Hari\", 20)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the data\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1750660563147,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "C-jDkgZ-eHzC",
    "outputId": "3b2c2f7f-2c5f-4584-e3e5-3d9f4f835f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Department|\n",
      "+-------+---+----------+\n",
      "|    Ram| 21|       CSE|\n",
      "|Dhinesh| 19|       ECE|\n",
      "| Refana| 19|       CSE|\n",
      "|   Banu| 20|       EEE|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "data = [(\"Ram\", 21, \"CSE\"),\n",
    "        (\"Dhinesh\", 19, \"ECE\"),\n",
    "        (\"Refana\", 19, \"CSE\"),\n",
    "        (\"Banu\", 20, \"EEE\")\n",
    "        ]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUtPC6ZAh9FI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1750661415950,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "i0XJBOmzjNZ9",
    "outputId": "7ad01bdd-c179-464a-a2c4-1f5ff0e06195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|   Name|Department|\n",
      "+-------+----------+\n",
      "|    Ram|       CSE|\n",
      "|Dhinesh|       ECE|\n",
      "| Refana|       CSE|\n",
      "|   Banu|       EEE|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "data = [(\"Ram\", 21, \"CSE\"),\n",
    "        (\"Dhinesh\", 19, \"ECE\"),\n",
    "        (\"Refana\", 19, \"CSE\"),\n",
    "        (\"Banu\", 20, \"EEE\")\n",
    "        ]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.select(\"Name\", \"Department\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1750661508636,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "3nSOx-O3jWNJ",
    "outputId": "47acc297-7c36-4cfd-ed0f-fd06e1ab9322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Department|\n",
      "+------+---+----------+\n",
      "|   Ram| 21|       CSE|\n",
      "|Refana| 19|       CSE|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "data = [(\"Ram\", 21, \"CSE\"),\n",
    "        (\"Dhinesh\", 19, \"ECE\"),\n",
    "        (\"Refana\", 19, \"CSE\"),\n",
    "        (\"Banu\", 20, \"EEE\")\n",
    "        ]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.filter(df[\"Department\"] == \"CSE\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1361,
     "status": "ok",
     "timestamp": 1750661558887,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "r9k168RAjy8K",
    "outputId": "845573c2-682a-47c5-e964-dd482575c3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Department|\n",
      "+------+---+----------+\n",
      "|   Ram| 21|       CSE|\n",
      "|Refana| 19|       CSE|\n",
      "+------+---+----------+\n",
      "\n",
      "+-------+---+----------+\n",
      "|   Name|Age|Department|\n",
      "+-------+---+----------+\n",
      "| Refana| 19|       CSE|\n",
      "|Dhinesh| 19|       ECE|\n",
      "|   Banu| 20|       EEE|\n",
      "|    Ram| 21|       CSE|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "data = [(\"Ram\", 21, \"CSE\"),\n",
    "        (\"Dhinesh\", 19, \"ECE\"),\n",
    "        (\"Refana\", 19, \"CSE\"),\n",
    "        (\"Banu\", 20, \"EEE\")\n",
    "        ]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.filter(df[\"Department\"] == \"CSE\").show()\n",
    "df.orderBy(\"Age\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3898,
     "status": "ok",
     "timestamp": 1750661613786,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "lGTmO2eGj8OT",
    "outputId": "d56b13f7-de07-4a4c-ec8c-c4b1fbaa0900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Department|\n",
      "+------+---+----------+\n",
      "|   Ram| 21|       CSE|\n",
      "|Refana| 19|       CSE|\n",
      "+------+---+----------+\n",
      "\n",
      "+-------+---+----------+\n",
      "|   Name|Age|Department|\n",
      "+-------+---+----------+\n",
      "| Refana| 19|       CSE|\n",
      "|Dhinesh| 19|       ECE|\n",
      "|   Banu| 20|       EEE|\n",
      "|    Ram| 21|       CSE|\n",
      "+-------+---+----------+\n",
      "\n",
      "Total Rows: 4\n",
      "+----------+\n",
      "|Department|\n",
      "+----------+\n",
      "|       ECE|\n",
      "|       CSE|\n",
      "|       EEE|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "data = [(\"Ram\", 21, \"CSE\"),\n",
    "        (\"Dhinesh\", 19, \"ECE\"),\n",
    "        (\"Refana\", 19, \"CSE\"),\n",
    "        (\"Banu\", 20, \"EEE\")\n",
    "        ]\n",
    "\n",
    "columns = [\"Name\", \"Age\", \"Department\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.filter(df[\"Department\"] == \"CSE\").show()\n",
    "df.orderBy(\"Age\").show()\n",
    "print(\"Total Rows:\", df.count())\n",
    "df.select(\"Department\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4WzntL7kWXD"
   },
   "outputs": [],
   "source": [
    "# Create a sample CSV file\n",
    "csv_data = \"\"\"Name,Age,Department\n",
    "Thiru,19,CSE\n",
    "Ram,21,EEE\n",
    "Kavi,20,IT\n",
    "Meena,22,CSE\n",
    "Arun,23,MECH\n",
    "\"\"\"\n",
    "\n",
    "with open(\"students.csv\", \"w\") as file:\n",
    "    file.write(csv_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1750666506003,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "jjZqalcZ0DTv",
    "outputId": "827e07a4-e5c6-45f0-cb2a-0c5b253495db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Department|\n",
      "+-----+---+----------+\n",
      "|Thiru| 19|       CSE|\n",
      "|  Ram| 21|       EEE|\n",
      "| Kavi| 20|        IT|\n",
      "|Meena| 22|       CSE|\n",
      "| Arun| 23|      MECH|\n",
      "+-----+---+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"LoadCSV data\").getOrCreate()\n",
    "df = spark.read.csv(\"/content/students.csv\", header=True, inferSchema=True)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1750667165021,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "U9a0jHoy3yxm",
    "outputId": "a1a67ab3-d141-4887-9c86-7f7da3ca7ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Department|\n",
      "+-----+---+----------+\n",
      "|Thiru| 19|       CSE|\n",
      "|  Ram| 21|       EEE|\n",
      "| Kavi| 20|        IT|\n",
      "|Meena| 22|       CSE|\n",
      "| Arun| 23|      MECH|\n",
      "+-----+---+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Department\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_manual = spark.read.csv(\"/content/students.csv\", header=True, schema=schema)\n",
    "df_manual.show()\n",
    "df_manual.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QT78VfUv5UME"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1750667192625,
     "user": {
      "displayName": "Ramachandiran G",
      "userId": "08249047918141802153"
     },
     "user_tz": -330
    },
    "id": "fU4wt5YV5T3o",
    "outputId": "d632bf9a-d258-4feb-e35f-94ab92f69681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Department|\n",
      "+-----+---+----------+\n",
      "|Thiru| 19|       CSE|\n",
      "|  Ram| 21|       EEE|\n",
      "| Kavi| 20|        IT|\n",
      "|Meena| 22|       CSE|\n",
      "| Arun| 23|      MECH|\n",
      "+-----+---+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Department\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_manual = spark.read.csv(\"/content/students.csv\", header=True, schema=schema)\n",
    "df_manual.show()\n",
    "df_manual.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m04FBuHb_bm7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUCodh4DEtnI5+siPAF6QV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
